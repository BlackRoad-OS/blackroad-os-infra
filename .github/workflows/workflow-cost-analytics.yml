name: ðŸ’° Workflow Cost Analytics & Optimization

on:
  schedule:
    - cron: '0 6 * * *'  # Daily at 6 AM
  workflow_dispatch:
    inputs:
      time_period:
        description: 'Analysis period (days)'
        required: false
        default: '30'
      generate_report:
        description: 'Generate detailed cost report'
        required: false
        type: boolean
        default: true

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  collect-usage-data:
    name: Collect GitHub Actions Usage Data
    runs-on: ubuntu-latest
    outputs:
      total_minutes: ${{ steps.calculate.outputs.total_minutes }}
      total_cost: ${{ steps.calculate.outputs.total_cost }}
      workflows_analyzed: ${{ steps.calculate.outputs.workflows }}
    steps:
      - name: ðŸ“¥ Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: ðŸ“Š Collect workflow usage
        run: |
          echo "Collecting workflow usage data for last ${{ github.event.inputs.time_period || 30 }} days..."

          DAYS=${{ github.event.inputs.time_period || 30 }}

          # Get all workflow runs from the period
          gh run list \
            --limit 1000 \
            --json name,conclusion,durationMs,createdAt,runnerGroup,runnerName \
            > /tmp/workflow-runs.json

          echo "Collected $(jq 'length' /tmp/workflow-runs.json) workflow runs"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: ðŸ’° Calculate costs
        id: calculate
        run: |
          cat > /tmp/cost-calculator.py << 'EOF'
import json
from datetime import datetime, timedelta
from collections import defaultdict

# GitHub Actions pricing (per minute)
PRICING = {
    'ubuntu-latest': 0.008,   # $0.008/min
    'ubuntu-20.04': 0.008,
    'ubuntu-22.04': 0.008,
    'macos-latest': 0.08,     # $0.08/min (10x more expensive!)
    'macos-11': 0.08,
    'macos-12': 0.08,
    'windows-latest': 0.016,  # $0.016/min (2x more expensive)
    'windows-2019': 0.016,
    'windows-2022': 0.016,
}

# Load workflow runs
with open('/tmp/workflow-runs.json') as f:
    runs = json.load(f)

# Filter to time period
days = int('${{ github.event.inputs.time_period || 30 }}')
cutoff = datetime.utcnow() - timedelta(days=days)

filtered_runs = []
for run in runs:
    try:
        created = datetime.fromisoformat(run['createdAt'].replace('Z', '+00:00'))
        if created > cutoff:
            filtered_runs.append(run)
    except:
        pass

print(f"Analyzing {len(filtered_runs)} runs from last {days} days")

# Calculate costs by workflow
workflow_costs = defaultdict(lambda: {
    'minutes': 0,
    'cost': 0,
    'runs': 0,
    'runner_types': defaultdict(int)
})

total_minutes = 0
total_cost = 0

for run in filtered_runs:
    name = run['name']
    duration_ms = run.get('durationMs', 0)

    if duration_ms == 0:
        continue

    minutes = duration_ms / 60000

    # Determine runner type (default to ubuntu)
    runner = run.get('runnerName', 'ubuntu-latest')

    # Map to pricing key
    runner_type = 'ubuntu-latest'
    if 'macos' in runner.lower() or 'mac' in runner.lower():
        runner_type = 'macos-latest'
    elif 'windows' in runner.lower() or 'win' in runner.lower():
        runner_type = 'windows-latest'

    cost_per_min = PRICING.get(runner_type, 0.008)
    cost = minutes * cost_per_min

    workflow_costs[name]['minutes'] += minutes
    workflow_costs[name]['cost'] += cost
    workflow_costs[name]['runs'] += 1
    workflow_costs[name]['runner_types'][runner_type] += 1

    total_minutes += minutes
    total_cost += cost

# Sort by cost (highest first)
sorted_workflows = sorted(
    workflow_costs.items(),
    key=lambda x: x[1]['cost'],
    reverse=True
)

print(f"\nTotal Usage: {total_minutes:.2f} minutes")
print(f"Total Cost: ${total_cost:.2f}")
print(f"\nTop 10 Most Expensive Workflows:")

for name, data in sorted_workflows[:10]:
    print(f"  {name}: ${data['cost']:.2f} ({data['minutes']:.0f} min, {data['runs']} runs)")

# Generate cost breakdown
cost_breakdown = {
    'total_minutes': round(total_minutes, 2),
    'total_cost': round(total_cost, 2),
    'workflows': len(workflow_costs),
    'period_days': days,
    'avg_cost_per_day': round(total_cost / days, 2),
    'avg_cost_per_workflow': round(total_cost / len(workflow_costs), 2) if workflow_costs else 0,
    'top_workflows': [
        {
            'name': name,
            'cost': round(data['cost'], 2),
            'minutes': round(data['minutes'], 2),
            'runs': data['runs'],
            'avg_cost_per_run': round(data['cost'] / data['runs'], 4),
            'runner_types': dict(data['runner_types'])
        }
        for name, data in sorted_workflows[:20]
    ]
}

# Save breakdown
with open('/tmp/cost-breakdown.json', 'w') as f:
    json.dump(cost_breakdown, f, indent=2)

# Output for GitHub Actions
import os
with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
    f.write(f"total_minutes={total_minutes:.2f}\n")
    f.write(f"total_cost={total_cost:.2f}\n")
    f.write(f"workflows={len(workflow_costs)}\n")

print(f"\nCost breakdown saved to /tmp/cost-breakdown.json")
EOF

          python3 /tmp/cost-calculator.py

  identify-cost-optimizations:
    name: Identify Cost Optimization Opportunities
    runs-on: ubuntu-latest
    needs: collect-usage-data
    outputs:
      optimizations: ${{ steps.optimize.outputs.optimizations }}
      potential_savings: ${{ steps.optimize.outputs.savings }}
    steps:
      - name: ðŸ’¡ Analyze cost optimization opportunities
        id: optimize
        run: |
          cat > /tmp/cost-optimizer.py << 'EOF'
import json

# Load cost breakdown
with open('/tmp/cost-breakdown.json') as f:
    breakdown = json.load(f)

optimizations = []
total_potential_savings = 0

for workflow in breakdown['top_workflows']:
    name = workflow['name']
    cost = workflow['cost']
    minutes = workflow['minutes']
    runs = workflow['runs']
    avg_cost = workflow['avg_cost_per_run']

    # Optimization 1: Switch expensive runners to cheaper ones
    runner_types = workflow['runner_types']
    if 'macos-latest' in runner_types or 'windows-latest' in runner_types:
        # macOS is 10x more expensive, Windows is 2x
        if 'macos-latest' in runner_types:
            mac_runs = runner_types['macos-latest']
            potential_savings = cost * 0.9  # 90% savings if switch to Ubuntu

            optimizations.append({
                'workflow': name,
                'type': 'expensive_runner',
                'current_runner': 'macos-latest',
                'suggested_runner': 'ubuntu-latest',
                'current_cost': round(cost, 2),
                'potential_savings': round(potential_savings, 2),
                'priority': 'high',
                'recommendation': 'Consider if macOS is required or if Ubuntu can be used'
            })
            total_potential_savings += potential_savings

        elif 'windows-latest' in runner_types:
            win_runs = runner_types['windows-latest']
            potential_savings = cost * 0.5  # 50% savings if switch to Ubuntu

            optimizations.append({
                'workflow': name,
                'type': 'expensive_runner',
                'current_runner': 'windows-latest',
                'suggested_runner': 'ubuntu-latest',
                'current_cost': round(cost, 2),
                'potential_savings': round(potential_savings, 2),
                'priority': 'medium',
                'recommendation': 'Consider if Windows is required or if Ubuntu can be used'
            })
            total_potential_savings += potential_savings

    # Optimization 2: High-frequency expensive workflows
    if runs > 100 and avg_cost > 0.05:  # >100 runs and >$0.05 per run
        potential_savings = cost * 0.3  # 30% savings from optimization

        optimizations.append({
            'workflow': name,
            'type': 'high_frequency',
            'runs': runs,
            'avg_cost_per_run': round(avg_cost, 4),
            'current_cost': round(cost, 2),
            'potential_savings': round(potential_savings, 2),
            'priority': 'high',
            'recommendation': 'High-frequency workflow - optimize caching and parallelization'
        })
        total_potential_savings += potential_savings

    # Optimization 3: Long-running workflows
    avg_minutes = minutes / runs if runs > 0 else 0
    if avg_minutes > 10:  # >10 min average
        potential_savings = cost * 0.4  # 40% savings from parallelization

        optimizations.append({
            'workflow': name,
            'type': 'long_running',
            'avg_minutes': round(avg_minutes, 2),
            'current_cost': round(cost, 2),
            'potential_savings': round(potential_savings, 2),
            'priority': 'medium',
            'recommendation': 'Long-running workflow - parallelize jobs and add caching'
        })
        total_potential_savings += potential_savings

# Sort by potential savings
optimizations.sort(key=lambda x: x['potential_savings'], reverse=True)

print(f"\nFound {len(optimizations)} cost optimization opportunities")
print(f"Total potential savings: ${total_potential_savings:.2f}/month")

print("\nTop optimizations:")
for opt in optimizations[:10]:
    print(f"  {opt['workflow']}: ${opt['potential_savings']:.2f} savings ({opt['type']})")

# Save optimizations
with open('/tmp/cost-optimizations.json', 'w') as f:
    json.dump({
        'optimizations': optimizations,
        'total_potential_savings': round(total_potential_savings, 2)
    }, f, indent=2)

# Output
import os
with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
    f.write(f"optimizations={len(optimizations)}\n")
    f.write(f"savings={total_potential_savings:.2f}\n")
EOF

          python3 /tmp/cost-optimizer.py

  generate-cost-report:
    name: Generate Cost Report
    runs-on: ubuntu-latest
    needs: [collect-usage-data, identify-cost-optimizations]
    if: github.event.inputs.generate_report != 'false'
    steps:
      - name: ðŸ“¥ Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: ðŸ“Š Generate comprehensive cost report
        run: |
          cat > /tmp/cost-report.md << 'EOF'
# ðŸ’° Workflow Cost Analytics Report

## Summary

**Analysis Period:** ${{ github.event.inputs.time_period || 30 }} days
**Total Usage:** ${{ needs.collect-usage-data.outputs.total_minutes }} minutes
**Total Cost:** $${{ needs.collect-usage-data.outputs.total_cost }}
**Workflows Analyzed:** ${{ needs.collect-usage-data.outputs.workflows }}

**Daily Average Cost:** $$(expr ${{ needs.collect-usage-data.outputs.total_cost }} / ${{ github.event.inputs.time_period || 30 }} | bc -l)

## Cost Optimization Opportunities

**Optimizations Found:** ${{ needs.identify-cost-optimizations.outputs.optimizations }}
**Potential Monthly Savings:** $${{ needs.identify-cost-optimizations.outputs.potential_savings }}

### Top Cost Optimizations

See `/tmp/cost-optimizations.json` for complete list.

## Recommendations

1. **Switch Expensive Runners**
   - macOS runners are 10x more expensive than Ubuntu
   - Windows runners are 2x more expensive than Ubuntu
   - Only use expensive runners when absolutely necessary

2. **Optimize High-Frequency Workflows**
   - Add caching to reduce run time
   - Parallelize independent jobs
   - Use concurrency limits to prevent duplicate runs

3. **Reduce Long-Running Workflows**
   - Break into smaller, parallelizable jobs
   - Add early exit conditions
   - Optimize slow steps (deps, builds, tests)

## Next Steps

- [ ] Review top 10 most expensive workflows
- [ ] Apply runner optimizations where possible
- [ ] Add caching to high-frequency workflows
- [ ] Monitor cost trends weekly

---

ðŸ’° **Cost analytics powered by AI optimization!**
EOF

          cat /tmp/cost-report.md

      - name: ðŸ’¾ Save cost report
        run: |
          mkdir -p docs/analytics

          cp /tmp/cost-breakdown.json docs/analytics/cost-breakdown.json
          cp /tmp/cost-optimizations.json docs/analytics/cost-optimizations.json
          cp /tmp/cost-report.md docs/analytics/COST_REPORT.md

          if git diff --quiet docs/analytics/; then
            echo "No changes to commit"
            exit 0
          fi

          git config user.name "BlackRoad Cost Analytics"
          git config user.email "cost-analytics@blackroad.systems"

          git add docs/analytics/
          git commit -m "docs: Update workflow cost analytics

Period: ${{ github.event.inputs.time_period || 30 }} days
Total cost: $${{ needs.collect-usage-data.outputs.total_cost }}
Potential savings: $${{ needs.identify-cost-optimizations.outputs.potential_savings }}

ðŸ’° Auto-generated by Cost Analytics" || true

          git push || true

  create-optimization-issues:
    name: Create Cost Optimization Issues
    runs-on: ubuntu-latest
    needs: [collect-usage-data, identify-cost-optimizations]
    if: needs.identify-cost-optimizations.outputs.potential_savings > 100
    steps:
      - name: ðŸ“ Create high-priority issues
        run: |
          # Create issue for high-savings optimizations
          gh issue create \
            --title "ðŸ’° Cost Optimization: $${{ needs.identify-cost-optimizations.outputs.potential_savings }}/month savings available" \
            --body "## Cost Optimization Opportunity

**Potential Monthly Savings:** $${{ needs.identify-cost-optimizations.outputs.potential_savings }}
**Current Monthly Cost:** $${{ needs.collect-usage-data.outputs.total_cost }}

### Top Optimizations

See cost analytics report for details: \`docs/analytics/COST_REPORT.md\`

### Immediate Actions

1. Review expensive runner usage (macOS, Windows)
2. Optimize high-frequency workflows
3. Add caching to long-running workflows

ðŸ’° **Cost analytics identifies \$$${{ needs.identify-cost-optimizations.outputs.potential_savings }}/month in savings!**" \
            --label "cost-optimization,high-priority"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        continue-on-error: true

  generate-cost-summary:
    name: Generate Cost Summary
    runs-on: ubuntu-latest
    needs: [collect-usage-data, identify-cost-optimizations]
    if: always()
    steps:
      - name: ðŸ“Š Create summary
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # ðŸ’° Workflow Cost Analytics

          ## Usage Summary

          **Period:** ${{ github.event.inputs.time_period || 30 }} days
          **Total Minutes:** ${{ needs.collect-usage-data.outputs.total_minutes }}
          **Total Cost:** $${{ needs.collect-usage-data.outputs.total_cost }}
          **Workflows:** ${{ needs.collect-usage-data.outputs.workflows }}

          ## Optimization Opportunities

          **Potential Savings:** $${{ needs.identify-cost-optimizations.outputs.potential_savings }}/month
          **Optimizations Found:** ${{ needs.identify-cost-optimizations.outputs.optimizations }}

          ## Cost Breakdown

          - Daily avg: $$(expr ${{ needs.collect-usage-data.outputs.total_cost }} / ${{ github.event.inputs.time_period || 30 }})
          - Per workflow: $$(expr ${{ needs.collect-usage-data.outputs.total_cost }} / ${{ needs.collect-usage-data.outputs.workflows }})

          ---

          ðŸ’° **Track costs, optimize spending, work smarter!**
          EOF
